# Domain B: Sensory & Physical Access (The Whare)

**Context:** These strategy nodes define the "Environmental Layer" of the Access Multiplier. They focus on reducing cognitive load, managing sensory input, and ensuring safety in the physical space.

---

## Strategy Node: Managing Listening Fatigue

<metadata>
id: dom_b_fatigue
name: Fatigue Management & Acoustic Triage
type: environmental_setup
target_constraint: ["auditory_fatigue", "behavioral_outbursts", "cognitive_exhaustion", "withdrawal"]
complexity: low
time_required: continuous_policy
</metadata>

### Core Logic (The "Why")
Auditory processing for DHH students is manual, not automatic. It burns glucose at a high rate. If we do not reduce the "Signal-to-Noise" ratio and provide brain breaks, the student will hit a cognitive wall (exhaustion/outburst) by 11:00 AM.

### Implementation Spec (System -> Routine -> Autonomy)
* **Phase 1: Teacher Setup (System Design)**
    * **Acoustic Triage:** Teacher installs tennis balls on chair legs, closes doors/windows *before* instruction, and turns off projector fans when not in use.
    * **Caption Default:** Teacher enables Closed Captions (CC) on the video player *before* the class enters. It is never an afterthought.
* **Phase 2: Class Routine (Shared Norms)**
    * **"Eyes/Ears Off" Blocks:** Teacher calls a "Brain Break" (2 mins). Rule: No looking, no listening. Heads down or eyes closed. This resets the sensory cortex.
    * **One Voice Rule:** Teacher strictly enforces that only one person speaks at a time to prevent "auditory clutter."
* **Phase 3: Student Autonomy (Independent Use)**
    * **The "Safe Break" Pass:** The student is allowed to initiate a 2-minute "ears off" break without asking permission, using a subtle card or signal, to self-manage fatigue.

### Evidence Guide (The Rubric)
* **Positive Signal (Success):**
    * Captions are on from the *first second* of the video.
    * Teacher creates silence (waits) before speaking, rather than shouting over noise.
    * "Brain Breaks" are scheduled, not just reaction to bad behavior.
* **Negative Signal (Failure Modes):**
    * Teacher asks "Do you need captions?" (Puts the burden on the student).
    * Turning captions on halfway through the video.
    * Teacher speaks while walking around the room (changing acoustic distance).

---

## Strategy Node: Visual Attention Cues

<metadata>
id: dom_b_attention
name: Visual Attention Signals
type: behavioral_routine
target_constraint: ["missed_instruction", "disengagement", "social_isolation"]
complexity: low
time_required: instant
</metadata>

### Core Logic (The "Why")
You cannot hear "Listen up" if you aren't looking. Auditory cues fail DHH students. We must install a "Visual Interrupt" system that secures eye contact *before* transmission begins.

### Implementation Spec (System -> Routine -> Autonomy)
* **Phase 1: Teacher Setup (System Design)**
    * **The Flash:** Teacher installs a desk lamp or uses the room light switch as the primary "Stop" signal.
    * **Shoulder Tap Protocol:** Teacher establishes that a gentle tap on the shoulder is the *only* way to get attention from behind (never waving or shouting).
* **Phase 2: Class Routine (Shared Norms)**
    * **The "Look-Back" Rule:** When the teacher signals, peers are trained to look at the teacher, then *look at the DHH student* to ensure they saw the signal.
    * **Wait-Time Anchor:** Teacher turns on the light signal and *counts to 3* (visually) before signing/speaking.
* **Phase 3: Student Autonomy (Independent Use)**
    * Student stops work immediately upon seeing the light.
    * Student orients body to face the source of information (Teacher or Peer).

### Evidence Guide (The Rubric)
* **Positive Signal (Success):**
    * Teacher waits for **full eye contact** from the DHH student before starting.
    * Peers naturally nudge or signal the DHH student if they miss the cue (Community care).
* **Negative Signal (Failure Modes):**
    * **"The Wave":** Teacher waves hands frantically in the student's peripheral vision (Visual Noise).
    * **Speak-and-Tap:** Teacher speaks the instruction *while* walking over to tap the student (Information is lost).
    * Relying on the bell/shout alone.

---

## Strategy Node: Organized & Focused (Cognitive Offloading)

<metadata>
id: dom_b_organization
name: Visual Organization & Cognitive Offloading
type: environmental_setup
target_constraint: ["executive_dysfunction", "anxiety", "slow_transition_times", "lost_materials"]
complexity: medium
time_required: preparation_needed
</metadata>

### Core Logic (The "Why")
DHH students use massive working memory for processing language. They have zero "spare RAM" for finding a pencil or remembering verbal instructions. We must "offload" organization into the visual environment.

### Implementation Spec (System -> Routine -> Autonomy)
* **Phase 1: Teacher Setup (System Design)**
    * **Photo-Labeling:** Bins/Resources are labeled with a **Photo of the contents**, not just text.
    * **Colour-Coding:** Subject folders match the timetable colours (e.g., Math is Blue on the timetable and Blue in the bin).
* **Phase 2: Class Routine (Shared Norms)**
    * **Visual Task Checklist:** For multi-step tasks, the teacher provides a printed or whiteboard checklist.
    * **Status Check:** Teacher asks: *"Show me your Blue Math Book"* (Visual check) before giving instructions.
* **Phase 3: Student Autonomy (Independent Use)**
    * Student uses a highlighter to physically mark off steps on the checklist as they finish.
    * Student retrieves materials independently using the visual cues (Photo match).

### Evidence Guide (The Rubric)
* **Positive Signal (Success):**
    * Instructions are given *after* materials are on the desk.
    * Checklists are physical (paper/board), not auditory lists.
    * "Where is..." questions are answered by pointing to the Visual Label, not verbal explanation.
* **Negative Signal (Failure Modes):**
    * Teacher gives instructions *while* students are getting materials (Rustling noise + Split attention).
    * "Clean up" instructions are vague ("Put it away") rather than specific ("Blue blocks in the Blue bin").

---

## Strategy Node: Monitoring (The Feedback Loop)

<metadata>
id: dom_b_monitoring
name: Proactive Monitoring & Visual Status
type: pedagogical_routine
target_constraint: ["masked_misunderstanding", "passive_nodding", "false_positive_agreement"]
complexity: medium
time_required: continuous_habit
</metadata>

### Core Logic (The "Why")
DHH students develop a "Survival Nod"â€”smiling and nodding even when they don't understand, to avoid social friction. The teacher must bypass this by checking *performance*, not *perception*.

### Implementation Spec (System -> Routine -> Autonomy)
* **Phase 1: Teacher Setup (System Design)**
    * **The Monitoring Rota:** Teacher marks a classroom map with 3 specific times to visit the DHH student (Start, Middle, End).
    * **Avoid Yes/No:** Teacher bans the question *"Do you understand?"*
* **Phase 2: Class Routine (Shared Norms)**
    * **Traffic Light Cards:** Students have Red/Yellow/Green cards on their desks. Red = "Stuck," Green = "Working."
    * **Phase 3 Check:** Teacher asks: *"Show me the first sentence"* (Performance check) rather than asking if they are okay.
* **Phase 3: Student Autonomy (Independent Use)**
    * **Photo Evidence:** Student takes a photo of their finished work/step with a tablet to "prove" completion visually.
    * Student flips their Traffic Light to Red immediately when stuck, rather than waiting for the teacher.

### Evidence Guide (The Rubric)
* **Positive Signal (Success):**
    * Teacher checks the DHH student *early* (within first 2 mins of independent work).
    * Questions are open-ended or directive ("Show me..."), never Yes/No.
    * Traffic lights are actively used, not just decorations.
* **Negative Signal (Failure Modes):**
    * **The Hover:** Teacher stands over the DHH student constantly (creates anxiety/dependency).
    * **The "Any Questions?" Shout:** Asking the whole class "Any questions?" and assuming silence means understanding.
    * Accepting the "Survival Nod."